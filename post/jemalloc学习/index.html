<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Jemalloc 学习 | hhdx's blog</title>
<meta name=keywords content><meta name=description content="本文基于 jemalloc-5.2.1 分支分析 jemalloc 内存管理的代码，以及 memory profiling 相关的实现。
jemalloc 结构
从高向低的介绍几个关键的结构体，以及他们的关联关系。


arena
主要的管理 allocation 结构，一般几个线程共用一个 arena。"><meta name=author content="hhdx"><link rel=canonical href=https://hhdx.xyz/post/jemalloc%E5%AD%A6%E4%B9%A0/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://hhdx.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://hhdx.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hhdx.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://hhdx.xyz/apple-touch-icon.png><link rel=mask-icon href=https://hhdx.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-cn href=https://hhdx.xyz/post/jemalloc%E5%AD%A6%E4%B9%A0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://hhdx.xyz/post/jemalloc%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="hhdx's blog"><meta property="og:title" content="Jemalloc 学习"><meta property="og:description" content="本文基于 jemalloc-5.2.1 分支分析 jemalloc 内存管理的代码，以及 memory profiling 相关的实现。
jemalloc 结构 从高向低的介绍几个关键的结构体，以及他们的关联关系。
arena 主要的管理 allocation 结构，一般几个线程共用一个 arena。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-11-10T18:50:44+08:00"><meta property="article:modified_time" content="2024-11-10T18:50:44+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Jemalloc 学习"><meta name=twitter:description content="本文基于 jemalloc-5.2.1 分支分析 jemalloc 内存管理的代码，以及 memory profiling 相关的实现。
jemalloc 结构
从高向低的介绍几个关键的结构体，以及他们的关联关系。


arena
主要的管理 allocation 结构，一般几个线程共用一个 arena。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hhdx.xyz/post/"},{"@type":"ListItem","position":2,"name":"Jemalloc 学习","item":"https://hhdx.xyz/post/jemalloc%E5%AD%A6%E4%B9%A0/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Jemalloc 学习","name":"Jemalloc 学习","description":"本文基于 jemalloc-5.2.1 分支分析 jemalloc 内存管理的代码，以及 memory profiling 相关的实现。\njemalloc 结构 从高向低的介绍几个关键的结构体，以及他们的关联关系。\narena 主要的管理 allocation 结构，一般几个线程共用一个 arena。\n","keywords":[],"articleBody":"本文基于 jemalloc-5.2.1 分支分析 jemalloc 内存管理的代码，以及 memory profiling 相关的实现。\njemalloc 结构 从高向低的介绍几个关键的结构体，以及他们的关联关系。\narena 主要的管理 allocation 结构，一般几个线程共用一个 arena。\nextent 一大块内存的管理结构，该内存通过 mmap 向 OS 申请，其中的成员 e_addr 字段指向真正管理的内存，数个页大小。一个 extent 可以当做是一次 large 类型的分配，也可以拆分成多个 small 的内存块。\nregion region 就是 small 的小内存块，一个 extent 会被划分为数个同样大小的 region。\nslab 一个 extent 会拆分成多个同样大小的内存，slab 的是基于 extent 的。\nbin 存储同样大小内存块指针的结构。\ntsd thread specific data，存储 tcache, arena 等线程关联的结构。\ntcache thread cache 的缩写，存储线程刚被释放的内存块，用于快速分配。\nsize class (可以忽略这段)\n这里介绍 jemalloc 中 size class 的约定，在 include/jemalloc/internal/sc.h 进行了详细的注释注解，一个 size class 代表一种大小的分配类型。\n首先忽略最小的几组 small size class。定义 size class group，每个 size class group 涵盖 (base, base * 2] 大小的内存分配，每个 group 里有 4 个 size class，定义为 SC_NGROUP，则其之间的差值为 delta = base/SC_NGROUP。也就是包含下面 4 个 size class:\n1 2 3 4 (base, base + 1*delta] (base + 1*delta, base + 2*delta] (base + 2*delta, base + 3*delta] (base + 3*delta, base + 4*delta] LG_QUANTUM 定义了分配的最小 alignment，这里 LG 代表取对数，jemalloc 将对齐大小定义为 16，所以 LG_QUANTUM 就是 4。但是为了避免浪费内存，还定义了 SC_LG_TINY_MIN 意为最小的分配大小，默认最小分配大小是 8，所以这值为 3。所以定义了一组 tiny size class: (0, 8]。\n另外对于 1 \u003c\u003c LG_QUANTUM，也就是 16 没法自成一个 size class group，因为如果把 16~32 之间再拆分成 4 组的话，就没法满足最小的 alignment。所以最初的几组定义为 pseudo group:\n1 2 3 4 5 1 * (1 \u003c\u003c LG_QUANTUM) 2 * (1 \u003c\u003c LG_QUANTUM) 3 * (1 \u003c\u003c LG_QUANTUM) * ... (although, as above, this \"...\" is empty in practice) SC_NGROUP * (1 \u003c\u003c LG_QUANTUM) 也就是\n1 2 3 4 (8, 16] (16, 32] (32, 48] (48, 64] 总结：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 tiny size classes: (0, 8] initial pseudo group: (8, 16] (16, 32] (32, 48] (48, 64] regulat group 0: (64, 80] (80, 96] (96, 112] (112, 128] regular group x: delta = base / SC_NGROUP =\u003e lg_delta = lg_base - SC_LG_NGROUP (1 \u003c\u003c lg_base) + 1 * (1 \u003c\u003c lg_delta) (1 \u003c\u003c lg_base) + 2 * (1 \u003c\u003c lg_delta) (1 \u003c\u003c lg_base) + 3 * (1 \u003c\u003c lg_delta) (1 \u003c\u003c lg_base) + 4 * (1 \u003c\u003c lg_delta) 另外大于 page size * group size 的大小的分配，被认为是 large size classes，默认情况下也就是大于 4K * 4 = 16K 的为 large size classes。\n分配与释放 small size 分配 首先会获取 tsd结构，使用 tsd中的 tcache结构的 tcache 尝试申请。这种 thread-specific 的数据使用 pthread_setspecific 和 pthread_getspecific 函数设置和获取。\ntcache 中使用 cache_bin 存储了多种 sized class 的内存块，比方说 tcache.bins_small[0] 用来存储 8 bytes 大小的内存块指针。如果顺利的话，直接就在这里分配出去了。\ntcache 如果没发服务分配的话，会使用 arena 进行分配，arena 用来管理 extent，也就是从系统 mmap 来的数个页大小的大内存块。如果 extent 被拆分用于 small size 内存的分配，那么这个 extent 也被称为 slab。\narena 使用 bin 来管理各个 sized class 的 extent，如果 tcache 没有了，就会从相应的 bin 里面取来，拆分成 region 填充 tcache，然后用来分配内存。bin 里面也有多种级别的 extent，会依次尝试 bin.slabcur，bin.slabs_nonfull，然后尝试 arena 级别的 extent 缓存：extents_dirty, extents_muzzy, extents_retained。\n如果 arena-\u003ebins[x] 里也没有 extent 了，那将会从 OS 处申请。\n释放 释放其实就是上面反过来的过程。\n性能调优 重要数据来源 jemalloc stats lg_page 逻辑页面大小 使用编译参数 -with-lg-page 调整 page size，以提高性能。\nissue 772\narena 个数 线程过多会导致 arena 锁竞争，适当的提高 arena 的数目可以减少。\ndirty decay, muzzy decay 通过这俩参数配置 extents 归还给系统的速度\noversize_threshold 超过这个临界值，会使用单独的 arena 分配，没有 tcache，一些情况下会导致 page fault 比较高。\nprofiling 相关 使用 jemalloc 的 memory profiling 需要在编译 configure 时添加参数 --enable-prof，这会在 jemalloc 中添加 profiling 相关的代码。profiling 的开启有两道开关，第一道是 opt_prof，标识是否启用 profiling 相关的代码；第二道开关是 prof_active ，设置了这个参数才开始记录，可以在程序运行中通过 malloc_ctl 设置开启，也可以在运行前通过 MALLOC_CONF 环境变量设置，这样启动时就打开了。\njemalloc 的内存分析也是基于采样的，与采样相关的一个关键参数是 lg_prof_sample，意为采样频率的指数，默认值是 19，也就是每分配 2**19 = 512KB 采样一次，实际上采样的间隔也不是固定的，通过一个算法使得平均值为 512KB。这样的做的是为了避免固定周期的采样带来的倾斜。\njemalloc 的采样机制，使得每 bytes 具有相同的概率被采样到；而不是根据分配的次数，根据分配的次数来采样会导致数据倾斜到小内存的采样。虽然根据 bytes 会让 sample 倾斜到大内存分配，但我们就是内存大小的 profile，所以这就是合理的。具体的机制可以参照这个文档 jemalloc profiling internals。\n采样的过程是这样的，每个 tsd 结构维护一个 bytes_until_sample 字段，在 fast path 分配时也会进行检查和更新，当小于 0 时就到慢路径处理分配。经过 je_malloc() -\u003e malloc_default() -\u003e imalloc() -\u003e imalloc_body() 的一串调用来到这里，会调用 prof_alloc_prep() 进行 prof 的准备，这个函数里面会再次调用 prof_sample_accum_update() -\u003e prof_sample_check() 确定 bytes_until_sample 是否满足要求（这里我感觉 bytes_until_sample 可能会被减了两次，通过 je_malloc 里快路径减一次，如果小于 0，或者没有从 tcache 分配成功，均会进入 malloc_default()，然后会被减第二次，没搞明白），不满足则返回值为 1 的指针；满足的话则会准备完整的 prof_tctx_t 结构，通过 prof_backtrace() 准备栈回溯。\n这里根据不同的编译选项会使用不同的方式来进行栈回溯，libgcc, libunwind, intrinsic gcc ，在 master 上还添加了新的 frame pointer 方式，这里有一些 MR 的讨论。通过讨论可以知道，虽然 fp 有较好的性能，但 Meta 目前还是以 libunwind 为默认，以避免在一些外部的闭源库里产生回溯不全的问题。\n栈回溯好后，会使用 prof_lookup() 函数查找是否有相同栈回溯的线程局部缓存 prof_tctx_t 和全局 prof_gctx_t 结构，没有的话，均会进行创建，确保每一种栈回溯在全局的哈希表 bt2gctx 和线程局部里的 tsd_t-\u003eprof_tdata-\u003ebt2tctx 里都有维护。\n他们都会互相联系起来，prof_gctx_t 里面有一个红黑树成员 tctxs 指向各个线程里具有相同 bt 的 tctx；tctx 里也有个结构 gctx 指向全局的；还有个全局变量的哈希表 bt2gctx 指向所有的 gctx。\n有点扯远了，prof_lookup() 返回了 tctx 后，如果值为 1 说明本次不采样，走正常路径分配内存；而如果大于 1 则认为本次采样，走 imalloc_sample() 函数里进行分配，该函数会将 small size class 的内存 promote 到 min large size class(也就是 1 \u003c\u003c (LG_PAGE + SC_LG_NGROUP) 的大小，默认就是 16KB)。为什么呢，为了方便的保存本次采样的上下文 tctx，正好在这个大小里，会直接关联 extent_t，通过 extent_t 结构里的字段保存 profiling 上下文。还可以很方便的根据指针通过 radix tree 找到这个该块地址对应的 extent_t 结构。每次在 free 比较大的内存时，都会进行该块内存是否被 sampled 的检查，如果是则删去相关的统计信息。\n总结 jemalloc 设计了多种级别的缓存，来减少分配的延迟，不论是在用户态分配，还是向内核态申请。强大性能的背后，也是复杂化的代价。\n参考 PROFILING_INTERNALS jemalloc 源码分析 Database · 内存管理 · JeMalloc-5.1.0 实现分析 Exploring Android Heap allocations in jemalloc ’new’ 2022-10-05-jemalloc.md ","wordCount":"2666","inLanguage":"zh-cn","datePublished":"2024-11-10T18:50:44+08:00","dateModified":"2024-11-10T18:50:44+08:00","author":{"@type":"Person","name":"hhdx"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://hhdx.xyz/post/jemalloc%E5%AD%A6%E4%B9%A0/"},"publisher":{"@type":"Organization","name":"hhdx's blog","logo":{"@type":"ImageObject","url":"https://hhdx.xyz/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hhdx.xyz/ accesskey=h title="hhdx's blog (Alt + H)">hhdx's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hhdx.xyz/ title=主页><span>主页</span></a></li><li><a href=https://hhdx.xyz/post/ title=归档><span>归档</span></a></li><li><a href=https://hhdx.xyz/tags/ title=标签><span>标签</span></a></li><li><a href=https://hhdx.xyz/underway/ title=施工中><span>施工中</span></a></li><li><a href=https://hhdx.xyz/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Jemalloc 学习</h1><div class=post-meta><span title='2024-11-10 18:50:44 +0800 +0800'>November 10, 2024</span>&nbsp;·&nbsp;hhdx</div></header><div class=post-content><p>本文基于 <a href=https://github.com/jemalloc/jemalloc/tree/5.2.1>jemalloc-5.2.1</a> 分支分析 jemalloc 内存管理的代码，以及 memory profiling 相关的实现。</p><h1 id=jemalloc-结构>jemalloc 结构<a hidden class=anchor aria-hidden=true href=#jemalloc-结构>#</a></h1><p>从高向低的介绍几个关键的结构体，以及他们的关联关系。</p><p><img alt="jemalloc new overview diagram" loading=lazy src=https://www.synacktiv.com/sites/default/files/inline-images/overview_0.png></p><p><img alt="Screen Shot 2022-09-25 at 11 31 51" loading=lazy src=https://user-images.githubusercontent.com/3775525/192127017-c6653401-c4ec-40d7-874b-97432bee0a80.png></p><h2 id=arena>arena<a hidden class=anchor aria-hidden=true href=#arena>#</a></h2><p>主要的管理 allocation 结构，一般几个线程共用一个 arena。</p><h2 id=extent>extent<a hidden class=anchor aria-hidden=true href=#extent>#</a></h2><p>一大块内存的<strong>管理结构</strong>，该内存通过 mmap 向 OS 申请，其中的成员 <code>e_addr</code> 字段指向真正管理的内存，数个页大小。一个 extent 可以当做是一次 large 类型的分配，也可以拆分成多个 small 的内存块。</p><h2 id=region>region<a hidden class=anchor aria-hidden=true href=#region>#</a></h2><p>region 就是 small 的小内存块，一个 extent 会被划分为数个<strong>同样大小</strong>的 region。</p><h2 id=slab>slab<a hidden class=anchor aria-hidden=true href=#slab>#</a></h2><p>一个 extent 会拆分成多个同样大小的内存，slab 的是基于 extent 的。</p><h2 id=bin>bin<a hidden class=anchor aria-hidden=true href=#bin>#</a></h2><p>存储同样大小内存块指针的结构。</p><h2 id=tsd>tsd<a hidden class=anchor aria-hidden=true href=#tsd>#</a></h2><p>thread specific data，存储 tcache, arena 等线程关联的结构。</p><h2 id=tcache>tcache<a hidden class=anchor aria-hidden=true href=#tcache>#</a></h2><p>thread cache 的缩写，存储线程刚被释放的内存块，用于快速分配。</p><h1 id=size-class>size class<a hidden class=anchor aria-hidden=true href=#size-class>#</a></h1><p>(可以忽略这段)</p><p>这里介绍 jemalloc 中 size class 的约定，在 <code>include/jemalloc/internal/sc.h</code> 进行了详细的注释注解，一个 size class 代表一种大小的分配类型。</p><p>首先忽略最小的几组 small size class。定义 size class group，每个 size class group 涵盖 (base, base * 2] 大小的内存分配，每个 group 里有 4 个 size class，定义为 <code>SC_NGROUP</code>，则其之间的差值为 <code>delta = base/SC_NGROUP</code>。也就是包含下面 4 个 size class:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>(base, base + 1*delta]
</span></span><span class=line><span class=cl>(base + 1*delta, base + 2*delta]
</span></span><span class=line><span class=cl>(base + 2*delta, base + 3*delta]
</span></span><span class=line><span class=cl>(base + 3*delta, base + 4*delta]
</span></span></code></pre></td></tr></table></div></div><p><code>LG_QUANTUM</code> 定义了分配的最小 alignment，这里 LG 代表取对数，jemalloc 将对齐大小定义为 16，所以 <code>LG_QUANTUM</code> 就是 4。但是为了避免浪费内存，还定义了 <code>SC_LG_TINY_MIN</code> 意为最小的分配大小，默认最小分配大小是 8，所以这值为 3。所以定义了一组 tiny size class: <code>(0, 8]</code>。</p><p>另外对于 <code>1 &lt;&lt; LG_QUANTUM</code>，也就是 16 没法自成一个 size class group，因为如果把 16~32 之间再拆分成 4 组的话，就没法满足最小的 alignment。所以最初的几组定义为 pseudo group:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>1 * (1 &lt;&lt; LG_QUANTUM)
</span></span><span class=line><span class=cl>2 * (1 &lt;&lt; LG_QUANTUM)
</span></span><span class=line><span class=cl>3 * (1 &lt;&lt; LG_QUANTUM)
</span></span><span class=line><span class=cl> *   ... (although, as above, this &#34;...&#34; is empty in practice)
</span></span><span class=line><span class=cl>SC_NGROUP * (1 &lt;&lt; LG_QUANTUM)
</span></span></code></pre></td></tr></table></div></div><p>也就是</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>(8,  16]
</span></span><span class=line><span class=cl>(16, 32]
</span></span><span class=line><span class=cl>(32, 48]
</span></span><span class=line><span class=cl>(48, 64]
</span></span></code></pre></td></tr></table></div></div><p>总结：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>tiny size classes:
</span></span><span class=line><span class=cl>(0, 8]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>initial pseudo group:
</span></span><span class=line><span class=cl>(8,  16]
</span></span><span class=line><span class=cl>(16, 32]
</span></span><span class=line><span class=cl>(32, 48]
</span></span><span class=line><span class=cl>(48, 64]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>regulat group 0:
</span></span><span class=line><span class=cl>(64, 80]
</span></span><span class=line><span class=cl>(80, 96]
</span></span><span class=line><span class=cl>(96, 112]
</span></span><span class=line><span class=cl>(112, 128]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>regular group x: delta = base / SC_NGROUP =&gt; lg_delta = lg_base - SC_LG_NGROUP
</span></span><span class=line><span class=cl>(1 &lt;&lt; lg_base) + 1 * (1 &lt;&lt; lg_delta)
</span></span><span class=line><span class=cl>(1 &lt;&lt; lg_base) + 2 * (1 &lt;&lt; lg_delta)
</span></span><span class=line><span class=cl>(1 &lt;&lt; lg_base) + 3 * (1 &lt;&lt; lg_delta)
</span></span><span class=line><span class=cl>(1 &lt;&lt; lg_base) + 4 * (1 &lt;&lt; lg_delta)
</span></span></code></pre></td></tr></table></div></div><p>另外大于 page size * group size 的大小的分配，被认为是 large size classes，默认情况下也就是大于 4K * 4 = 16K 的为 large size classes。</p><h1 id=分配与释放>分配与释放<a hidden class=anchor aria-hidden=true href=#分配与释放>#</a></h1><h2 id=small-size-分配>small size 分配<a hidden class=anchor aria-hidden=true href=#small-size-分配>#</a></h2><p>首先会获取 <code>tsd</code>结构，使用 <code>tsd</code>中的 <code>tcache</code>结构的 tcache 尝试申请。这种 thread-specific 的数据使用 <code>pthread_setspecific</code> 和 <code>pthread_getspecific</code> 函数设置和获取。</p><p><code>tcache</code> 中使用 <code>cache_bin</code> 存储了多种 sized class 的内存块，比方说 <code>tcache.bins_small[0]</code> 用来存储 8 bytes 大小的内存块指针。如果顺利的话，直接就在这里分配出去了。</p><p><code>tcache</code> 如果没发服务分配的话，会使用 <code>arena</code> 进行分配，<code>arena</code> 用来管理 <code>extent</code>，也就是从系统 <code>mmap</code> 来的数个页大小的大内存块。如果 <code>extent</code> 被拆分用于 small size 内存的分配，那么这个 <code>extent</code> 也被称为 <code>slab</code>。</p><p><code>arena</code> 使用 <code>bin</code> 来管理各个 sized class 的 <code>extent</code>，如果 tcache 没有了，就会从相应的 <code>bin</code> 里面取来，拆分成 <code>region</code> 填充 <code>tcache</code>，然后用来分配内存。<code>bin</code> 里面也有多种级别的 <code>extent</code>，会依次尝试 <code>bin.slabcur</code>，<code>bin.slabs_nonfull</code>，然后尝试 <code>arena</code> 级别的 <code>extent</code> 缓存：<code>extents_dirty</code>, <code>extents_muzzy</code>, <code>extents_retained</code>。</p><p>如果 <code>arena->bins[x]</code> 里也没有 <code>extent</code> 了，那将会从 OS 处申请。</p><h2 id=释放>释放<a hidden class=anchor aria-hidden=true href=#释放>#</a></h2><p>释放其实就是上面反过来的过程。</p><h1 id=性能调优>性能调优<a hidden class=anchor aria-hidden=true href=#性能调优>#</a></h1><h2 id=重要数据来源-jemalloc-stats>重要数据来源 jemalloc stats<a hidden class=anchor aria-hidden=true href=#重要数据来源-jemalloc-stats>#</a></h2><h2 id=lg_page-逻辑页面大小>lg_page 逻辑页面大小<a hidden class=anchor aria-hidden=true href=#lg_page-逻辑页面大小>#</a></h2><p>使用编译参数 <code>-with-lg-page</code> 调整 page size，以提高性能。</p><p><a href=https://github.com/jemalloc/jemalloc/issues/772>issue 772</a></p><h2 id=arena-个数>arena 个数<a hidden class=anchor aria-hidden=true href=#arena-个数>#</a></h2><p>线程过多会导致 arena 锁竞争，适当的提高 arena 的数目可以减少。</p><h2 id=dirty-decay-muzzy-decay>dirty decay, muzzy decay<a hidden class=anchor aria-hidden=true href=#dirty-decay-muzzy-decay>#</a></h2><p>通过这俩参数配置 extents 归还给系统的速度</p><h2 id=oversize_threshold>oversize_threshold<a hidden class=anchor aria-hidden=true href=#oversize_threshold>#</a></h2><p>超过这个临界值，会使用单独的 arena 分配，没有 tcache，一些情况下会导致 page fault 比较高。</p><h1 id=profiling-相关>profiling 相关<a hidden class=anchor aria-hidden=true href=#profiling-相关>#</a></h1><p>使用 jemalloc 的 memory profiling 需要在编译 configure 时添加参数 <code>--enable-prof</code>，这会在 jemalloc 中添加 profiling 相关的代码。profiling 的开启有两道开关，第一道是 <code>opt_prof</code>，标识是否启用 profiling 相关的代码；第二道开关是 <code>prof_active</code> ，设置了这个参数才开始记录，可以在程序运行中通过 <code>malloc_ctl</code> 设置开启，也可以在运行前通过 <code>MALLOC_CONF</code> 环境变量设置，这样启动时就打开了。</p><p>jemalloc 的内存分析也是基于采样的，与采样相关的一个关键参数是 <code>lg_prof_sample</code>，意为采样频率的指数，默认值是 19，也就是每分配 <code>2**19 = 512KB</code> 采样一次，实际上采样的间隔也不是固定的，<a href=https://github.com/jemalloc/jemalloc/blob/5.2.1/src/prof.c#L1140>通过一个算法使得平均值为 512KB</a>。这样的做的是为了避免固定周期的采样带来的倾斜。</p><p>jemalloc 的采样机制，使得每 bytes 具有相同的概率被采样到；而不是根据分配的次数，根据分配的次数来采样会导致数据倾斜到小内存的采样。虽然根据 bytes 会让 sample 倾斜到大内存分配，但我们就是内存大小的 profile，所以这就是合理的。具体的机制可以参照这个文档 <a href=https://github.com/jemalloc/jemalloc/blob/dev/doc_internal/PROFILING_INTERNALS.md>jemalloc profiling internals</a>。</p><p>采样的过程是这样的，每个 tsd 结构维护一个 <code>bytes_until_sample</code> 字段，在 fast path 分配时也会进行检查和更新，当小于 0 时就到慢路径处理分配。经过 <code>je_malloc() -> malloc_default() -> imalloc() -> imalloc_body()</code> 的一串调用来到<a href=https://github.com/jemalloc/jemalloc/blob/5.2.1/src/jemalloc.c#L2116>这里</a>，会调用 <code>prof_alloc_prep()</code> 进行 prof 的准备，这个函数里面会再次调用 <code>prof_sample_accum_update() -> prof_sample_check()</code> 确定 <code>bytes_until_sample</code> 是否满足要求（这里我感觉 <code>bytes_until_sample</code> 可能会被减了两次，通过 <code>je_malloc</code> 里快路径减一次，如果小于 0，或者没有从 tcache 分配成功，均会进入 <code>malloc_default()</code>，然后会被减第二次，没搞明白），不满足则返回值为 1 的指针；满足的话则会准备完整的 <code>prof_tctx_t</code> 结构，通过 <code>prof_backtrace()</code> 准备栈回溯。</p><blockquote><p>这里根据不同的编译选项会使用不同的方式来进行栈回溯，<code>libgcc</code>, <code>libunwind</code>, <code>intrinsic gcc</code> ，在 master 上还添加了新的 <code>frame pointer</code> 方式，<a href=https://github.com/jemalloc/jemalloc/pull/2712>这里</a>有一些 MR 的讨论。通过讨论可以知道，虽然 fp 有较好的性能，但 Meta 目前还是以 <code>libunwind</code> 为默认，以避免在一些外部的闭源库里产生回溯不全的问题。</p></blockquote><p>栈回溯好后，会使用 <code>prof_lookup()</code> 函数查找是否有相同栈回溯的线程局部缓存 <code>prof_tctx_t</code> 和全局 <code>prof_gctx_t</code> 结构，没有的话，均会进行创建，确保每一种栈回溯在全局的哈希表 bt2gctx 和线程局部里的 <code>tsd_t->prof_tdata->bt2tctx</code> 里都有维护。</p><p>他们都会互相联系起来，<code>prof_gctx_t</code> 里面有一个红黑树成员 <code>tctxs</code> 指向各个线程里具有相同 bt 的 tctx；tctx 里也有个结构 <code>gctx</code> 指向全局的；还有个全局变量的哈希表 <code>bt2gctx</code> 指向所有的 gctx。</p><p><img alt=image-20241207231815297 loading=lazy src=https://raw.githubusercontent.com/clxsh/pics/master/imgimage-20241207231815297.png></p><p>有点扯远了，<code>prof_lookup()</code> 返回了 <code>tctx</code> 后，如果值为 1 说明本次不采样，走正常路径分配内存；而如果大于 1 则认为本次采样，走 <code>imalloc_sample()</code> 函数里进行分配，该函数会将 small size class 的内存 promote 到 min large size class(也就是 <code>1 &lt;&lt; (LG_PAGE + SC_LG_NGROUP)</code> 的大小，默认就是 16KB)。为什么呢，为了方便的保存本次采样的上下文 tctx，正好在这个大小里，会直接关联 <code>extent_t</code>，通过 <code>extent_t</code> 结构里的字段保存 profiling 上下文。还可以很方便的根据指针通过 radix tree 找到这个该块地址对应的 <code>extent_t</code> 结构。每次在 free 比较大的内存时，都会进行该块内存是否被 sampled 的检查，如果是则删去相关的统计信息。</p><h1 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h1><p>jemalloc 设计了多种级别的缓存，来减少分配的延迟，不论是在用户态分配，还是向内核态申请。强大性能的背后，也是复杂化的代价。</p><h1 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h1><ol><li><a href=https://github.com/jemalloc/jemalloc/blob/dev/doc_internal/PROFILING_INTERNALS.md>PROFILING_INTERNALS</a></li><li><a href=https://youjiali1995.github.io/allocator/jemalloc/>jemalloc 源码分析</a></li><li><a href=http://mysql.taobao.org/monthly/2019/08/04/>Database · 内存管理 · JeMalloc-5.1.0 实现分析</a></li><li><a href=https://www.synacktiv.com/publications/exploring-android-heap-allocations-in-jemalloc-new>Exploring Android Heap allocations in jemalloc &rsquo;new&rsquo;</a></li><li><a href=https://github.com/yfractal/blog/blob/master/blog/2022-10-05-jemalloc.md#small-memory-allocation>2022-10-05-jemalloc.md</a></li></ol></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://hhdx.xyz/>hhdx's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>